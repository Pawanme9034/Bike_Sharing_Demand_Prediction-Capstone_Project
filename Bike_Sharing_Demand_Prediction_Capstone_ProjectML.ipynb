{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "T5CmagL3EC8N",
        "qjKvONjwE8ra",
        "TIqpNgepFxVj",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pawanme9034/Bike_Sharing_Demand_Prediction-Capstone_Project/blob/main/Bike_Sharing_Demand_Prediction_Capstone_ProjectML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Bike Sharing Demand Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name-**  Pawan Kumar Singh\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Pawanme9034/Bike_Sharing_Demand_Prediction-Capstone_Project/blob/main/Bike_Sharing_Demand_Prediction_Capstone_ProjectML.ipynb"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement is the prediction of bike count required at each hour for the stable supply of rental bikes.\n",
        ""
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dByMsuzT8Tnw"
      },
      "source": [
        "#let's import the modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from datetime import datetime\n",
        "import datetime as dt\n",
        "\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "import requests\n",
        "from io import StringIO\n",
        "# uploading data through Github directly\n",
        "url = \"https://raw.githubusercontent.com/Pawanme9034/Bike_Sharing_Demand_Prediction-Capstone_Project/main/SeoulBikeData.csv\"\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:66.0) Gecko/20100101 Firefox/66.0\"}\n",
        "req = requests.get(url, headers=headers)\n",
        "data = StringIO(req.text)\n",
        "\n",
        "bike_df=pd.read_csv(data)"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "bike_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "bike_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "bike_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "value=len(bike_df[bike_df.duplicated()])\n",
        "value"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "bike_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. This Dataset contains 8760 lines and 14 columns.\n",
        "2. the data is orgenized and there are timestamp.\n",
        "3. there are no missing or null values in dataset.\n",
        "4. dtypes: float64(6), int64(4), object(4)\n",
        "5. memory usage: 848.3+ KB\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "bike_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "bike_df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Date** : *The date of the day, during 365 days from 01/12/2017 to 30/11/2018, formating in DD/MM/YYYY, type : str*, we need to convert into datetime format.\n",
        "\n",
        "**Rented Bike Count** : *Number of rented bikes per hour which our dependent variable and we need to predict that, type : int*\n",
        "\n",
        "**Hour**: *The hour of the day, starting from 0-23 it's in a digital time format, type : int, we need to convert it into category data type.*\n",
        "\n",
        "**Temperature(°C)**: *Temperature in Celsius, type : Float*\n",
        "\n",
        "**Humidity(%)**: *Humidity in the air in %, type : int*\n",
        "\n",
        "**Wind speed (m/s)** : *Speed of the wind in m/s, type : Float*\n",
        "\n",
        "**Visibility (10m)**: *Visibility in m, type : int*\n",
        "\n",
        "**Dew point temperature(°C)**: *Temperature at the beggining of the day, type : Float*\n",
        "\n",
        "**Solar Radiation (MJ/m2)**: *Sun contribution, type : Float*\n",
        "\n",
        "**Rainfall(mm)**: *Amount of raining in mm, type : Float*\n",
        "\n",
        "**Snowfall (cm)**: *Amount of snowing in cm, type : Float*\n",
        "\n",
        "**Seasons**: *Season of the year, type : str, there are only 4 season's in data *.\n",
        "\n",
        "**Holiday**: *If the day  is holiday period or not, type: str*\n",
        "\n",
        "**Functioning Day**: *If the day is a Functioning Day or not, type : str* *italicized text* **bold text**\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "print(bike_df.apply(lambda col: col.unique()))"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print the unique value\n",
        "bike_df.nunique()"
      ],
      "metadata": {
        "id": "i4mWRdXxa2V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "#Rename the complex columns name\n",
        "bike_df=bike_df.rename(columns={'Rented Bike Count':'Rented_Bike_Count',\n",
        "                                'Temperature(°C)':'Temperature',\n",
        "                                'Temperature(�C)':'Temperature',\n",
        "                                'Humidity(%)':'Humidity',\n",
        "                                'Wind speed (m/s)':'Wind_speed',\n",
        "                                'Visibility (10m)':'Visibility',\n",
        "                                'Dew point temperature(°C)':'Dew_point_temperature',\n",
        "                                'Dew point temperature(�C)':'Dew_point_temperature',\n",
        "                                'Solar Radiation (MJ/m2)':'Solar_Radiation',\n",
        "                                'Rainfall(mm)':'Rainfall',\n",
        "                                'Snowfall (cm)':'Snowfall',\n",
        "                                'Functioning Day':'Functioning_Day'})"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df.columns"
      ],
      "metadata": {
        "id": "BXmGErKVQP-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df.head(2)"
      ],
      "metadata": {
        "id": "DJDFGfOGQxuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the \"Date\" column into three \"year\",\"month\",\"day\" column\n",
        "bike_df['Date'] = bike_df['Date'].apply(lambda x:dt.datetime.strptime(x,\"%d/%m/%Y\"))\n",
        "bike_df['Date']"
      ],
      "metadata": {
        "id": "vNKBcgGjS-OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df['year'] = bike_df['Date'].dt.year\n",
        "bike_df['month'] = bike_df['Date'].dt.month\n",
        "bike_df['day'] = bike_df['Date'].dt.day_name()"
      ],
      "metadata": {
        "id": "eFbxRfToVKUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a new column of \"weekdays_weekend\" and drop the column \"Date\",\"day\",\"year\"\n",
        "bike_df['weekdays_weekend']=bike_df['day'].apply(lambda x : 1 if x=='Saturday' or x=='Sunday' else 0 )\n",
        "bike_df=bike_df.drop(columns=['Date','day','year'],axis=1)\n"
      ],
      "metadata": {
        "id": "FGqDhH03VPKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df['weekdays_weekend'].value_counts()"
      ],
      "metadata": {
        "id": "d45w6rYBYjQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***So we convert the \"date\" column into 3 different column i.e \"year\",\"month\",\"day\".***\n",
        "* ***The \"year\" column in our data set is basically contain the 2 unique number contains the details of from 2017 december to 2018 november so if i consider this is a one year then we don't need the \"year\" column so we drop it***.\n",
        "* ***The other column \"day\", it contains the details about the each day of the month, for our relevence we don't need each day of each month data but we need the data about, if a day is a weekday or a weekend so we convert it into this format and drop the \"day\" column***."
      ],
      "metadata": {
        "id": "ryZ5NezGVVhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df.head(2)"
      ],
      "metadata": {
        "id": "_jD1tK0tVT3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the int64 column into catagory column\n",
        "cols=['Hour','month','weekdays_weekend']\n",
        "for col in cols:\n",
        "  bike_df[col]=bike_df[col].astype('category')"
      ],
      "metadata": {
        "id": "Wlb1NivUWc12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assign the numerical coulmn to variavle\n",
        "numerical_columns=list(bike_df.select_dtypes(['int64','float64']).columns)\n",
        "numerical_features=pd.Index(numerical_columns)\n",
        "numerical_features"
      ],
      "metadata": {
        "id": "vYNveBExrwjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df.head(2)"
      ],
      "metadata": {
        "id": "J3O1h8y8p6XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df.info()\n"
      ],
      "metadata": {
        "id": "tkQ--QZTzgtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Y2fQIv7abr57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df.head(2)"
      ],
      "metadata": {
        "id": "izoadURwaPSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "fig,ax=plt.subplots(figsize=(20,8))\n",
        "sns.barplot(data=bike_df,x='month',y='Rented_Bike_Count',ax=ax,capsize=.2,hue='Seasons')\n",
        "ax.set(title='Count of Rented bikes acording to Month ')"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hourly Distribution"
      ],
      "metadata": {
        "id": "RDlem-0-U4pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "fig,ax=plt.subplots(figsize=(20,8))\n",
        "sns.pointplot(data=bike_df,x='Hour',y='Rented_Bike_Count',hue='weekdays_weekend',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to weekdays_weekend ')"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df.head(2)"
      ],
      "metadata": {
        "id": "45g3-S3mgYhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "fig, ax = plt.subplots(figsize=(20, 8))\n",
        "\n",
        "sns.barplot(data=bike_df,x='Seasons',y='Rented_Bike_Count',ax=ax,capsize=.2)\n",
        "ax.set(title='Count of Rented Bikes According to Weekdays/Weekends')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "# Specify line colors using the \"color\" parameter\n",
        "# sns.scatterplot(tips['total_bill'],tips['tip'],hue=df['sex'],style=df['smoker'],size=df['size'])\n",
        "sns.scatterplot(data=bike_df, y='Rented_Bike_Count', x='Snowfall')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the style of the plot\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "# Create the scatter plot\n",
        "sns.scatterplot(data=bike_df, x='Temperature', y='Rented_Bike_Count', color='blue', alpha=0.5, marker='o', s=50)\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Temperature (°C)')\n",
        "plt.ylabel('Rented Bike Count')\n",
        "plt.title('Scatter Plot of Temperature vs Rented Bike Count')\n",
        "plt.legend(['Bike Data'], loc='upper right')\n",
        "\n",
        "# Adjust the plot aesthetics\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the style of the plot\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "# Create the line plot\n",
        "sns.lineplot(data=bike_df, x='Solar_Radiation', y='Rented_Bike_Count', color='green')\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Solar Radiation')\n",
        "plt.ylabel('Mean Rented Bike Count')\n",
        "plt.title('Mean Rented Bike Count by Solar Radiation')\n",
        "\n",
        "# Adjust the plot aesthetics\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "bike_df.groupby('Wind_speed').mean()['Rented_Bike_Count'].plot()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "for col in numerical_features:\n",
        "  fig,ax=plt.subplots(figsize=(10,6))\n",
        "  sns.regplot(x=bike_df[col],y=bike_df['Rented_Bike_Count'],scatter_kws={\"color\": 'orange'}, line_kws={\"color\": \"black\"})"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "df_col=bike_df.columns\n",
        "for col in df_col:\n",
        "  if bike_df[col].dtype != object:\n",
        "    sns.distplot(bike_df[col])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df.corr()['Rented_Bike_Count']"
      ],
      "metadata": {
        "id": "LZ4ptUJns4Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "## plot the Correlation matrix\n",
        "plt.figure(figsize=(20,8))\n",
        "correlation=bike_df.corr()\n",
        "mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
        "sns.heatmap((correlation),mask=mask, annot=True,cmap='coolwarm')"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "# sns.pairplot(bike_df,hue='Seasons',corner=True)"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assumption : Observations are identically distributed(all the elemets in the test have equail probability to ocure)"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cheking Histogram\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.hist(bike_df['Rented_Bike_Count'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YfeIXZNE-vcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Help from Python\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "DataToTest = bike_df['Rented_Bike_Count']\n",
        "\n",
        "stat, p = shapiro(DataToTest)\n",
        "\n",
        "print('stat=%.2f, p=%.30f' % (stat, p))\n",
        "\n",
        "if p > 0.05:\n",
        "    print('Normal distribution')\n",
        "else:\n",
        "    print('Not a normal distribution')"
      ],
      "metadata": {
        "id": "3wFvj177AtNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normality test using Shapiro-Wilk Test : tests If data is normally distributed"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Shapiro-Wilk test is used to assess the normality of a dataset. It helps determine whether the data follows a normal distribution or deviates significantly from it."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asumption - Identical and Normal Distribution"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df.corr()['Rented_Bike_Count']"
      ],
      "metadata": {
        "id": "uvpmAN-nF-Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FirstSample =bike_df[1:30]['Rented_Bike_Count']\n",
        "SecondSample = bike_df[1:30]['Temperature']\n",
        "\n",
        "plt.plot(FirstSample,SecondSample)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GeP0yyFcFu6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Spearman Rank Correlation\n",
        "from scipy.stats import spearmanr\n",
        "stat, p = spearmanr(FirstSample, SecondSample)\n",
        "\n",
        "print('stat=%.3f, p=%5f' % (stat, p))\n",
        "if p > 0.05:\n",
        "    print('independent samples')\n",
        "else:\n",
        "    print('dependent samples')"
      ],
      "metadata": {
        "id": "8bSN0gsGGRFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pearson correlation\n",
        "from scipy.stats import pearsonr\n",
        "stat, p = pearsonr(FirstSample, SecondSample)\n",
        "\n",
        "print('stat=%.3f, p=%5f' % (stat, p))\n",
        "if p > 0.05:\n",
        "    print('independent samples')\n",
        "else:\n",
        "    print('dependent samples')"
      ],
      "metadata": {
        "id": "VJn_-wBYGr0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "te7_e6AaGlT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer.\n",
        "Correlation Test - Pearson and Spearman’s Rank Correlation"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson correlation is used to measure the strength and direction of a linear relationship between two continuous variables.\n",
        "\n",
        "Spearman's rank correlation is used to measure the strength and direction of a monotonic relationship between two variables, which can be continuous or ranked."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contingency_data = pd.crosstab(bike_df['Seasons'], bike_df['Holiday'],margins = False)\n",
        "contingency_data"
      ],
      "metadata": {
        "id": "d-d5G-0CJYlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import chi2_contingency\n",
        "import scipy.stats as stats\n",
        "\n",
        "\n",
        "# Perform the chi-square test\n",
        "chi2, p_value, dof, expected = stats.chi2_contingency(contingency_data)\n",
        "\n",
        "# Print the chi-square test result\n",
        "print(\"Chi-square statistic:\", chi2)\n",
        "print(\"p-value:\", p_value)\n",
        "print(\"Degrees of freedom:\", dof)\n",
        "\n",
        "if p > 0.05:\n",
        "    print('independent categories')\n",
        "else:\n",
        "    print('dependent categories')"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the chi-square test results, the chi-square statistic is 122.59, the p-value is approximately 2.14e-26, and the degrees of freedom is 3.\n",
        "\n",
        "Since the p-value is extremely small (smaller than the typical significance level of 0.05), we can reject the null hypothesis of independence between the \"Seasons\" and \"Holiday\" variables. This suggests that there is a significant association or dependency between the two variables in the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the occurrence of seasons and holidays in the dataset is not independent of each other. The variables \"Seasons\" and \"Holiday\" are related, and the difference in their frequencies is statistically significant."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install missingno"
      ],
      "metadata": {
        "id": "-6Lq2vYAPPiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import missingno as msno\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have a DataFrame named bike_df\n",
        "msno.matrix(bike_df)\n"
      ],
      "metadata": {
        "id": "0hRF3Fp5PMAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "print(bike_df.isna().sum())"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lockely there are no missing values in the dataset.so i don't use any missing value imputation technique"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rented_Bike_Count is skewed so i use boxplot"
      ],
      "metadata": {
        "id": "TzdxyCb4WDAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df.skew()"
      ],
      "metadata": {
        "id": "9NSvaBAdXUdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df['Rented_Bike_Count'].skew()"
      ],
      "metadata": {
        "id": "gxwhguzVXISQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "#Boxplot of Rented Bike Count to check outliers\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.ylabel('Rented_Bike_Count')\n",
        "sns.boxplot(x=bike_df['Rented_Bike_Count'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above boxplot shows that we have detect outliers in Rented Bike Count column"
      ],
      "metadata": {
        "id": "dnMdxaLOMdNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.xlabel('Rented Bike Count')\n",
        "plt.ylabel('Density')\n",
        "\n",
        "ax = sns.distplot(np.sqrt(bike_df['Rented_Bike_Count']), color=\"purple\")\n",
        "ax.axvline(np.sqrt(bike_df['Rented_Bike_Count']).mean(), color='blue', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(np.sqrt(bike_df['Rented_Bike_Count']).median(), color='green', linestyle='dashed', linewidth=2)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "e7s97FLUQOn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#After applying sqrt on Rented Bike Count check wheater we still have outliers\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "plt.ylabel('Rented_Bike_Count')\n",
        "sns.boxplot(x=np.sqrt(bike_df['Rented_Bike_Count']))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I06GwwIpQZaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "np.sqrt(bike_df['Rented_Bike_Count']) will return a new Series object with the square root of each value in the 'Rented_Bike_Count' column.\n",
        "\n",
        "\n",
        "This transformation is often applied to data to reduce skewness, as taking the square root can help normalize the distribution and make it more symmetric.\n"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Assign all catagoriacla features to a variable\n",
        "categorical_features = bike_df.select_dtypes(include=['object', 'category']).columns\n",
        "categorical_features"
      ],
      "metadata": {
        "id": "JYhjt2eSvGJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df_copy = pd.get_dummies(bike_df, columns=categorical_features, drop_first=True)\n"
      ],
      "metadata": {
        "id": "1Sa6z0tHwcjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-hot encoding is a common preprocessing step for categorical features in machine learning models. By converting categorical variables into binary columns, it allows machine learning algorithms to work with categorical data more effectively."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "7hZjnsqpBbme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df_copy.columns"
      ],
      "metadata": {
        "id": "Ouq3k8We9kXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train test split"
      ],
      "metadata": {
        "id": "flkwMZrbY-rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = bike_df_copy.drop(columns=['Rented_Bike_Count'], axis=1)\n",
        "y = np.sqrt(bike_df_copy['Rented_Bike_Count'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=0)\n"
      ],
      "metadata": {
        "id": "TfqK-7xC9kG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with the following function we can select highly correlated features\n",
        "# it will remove the first feature that is correlated with anything other feature\n",
        "\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()  # Set of all the names of correlated columns\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if (corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
        "                colname = corr_matrix.columns[i]  # getting the name of column\n",
        "                col_corr.add(colname)\n",
        "    return col_corr"
      ],
      "metadata": {
        "id": "_jIwgk7JBAOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_features = correlation(X_train, 0.7)\n",
        "len(set(corr_features))"
      ],
      "metadata": {
        "id": "4p48O1okBO4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_features"
      ],
      "metadata": {
        "id": "6rCqZ49LBUpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "X_train.drop(corr_features,axis=1)\n",
        "X_test.drop(corr_features,axis=1)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlated features are features that exhibit a high degree of linear relationship or dependency between them. Having highly correlated features can introduce multicollinearity in a model, which can affect the model's performance and interpretability.\n",
        "\n",
        "Correlated features are features that exhibit a high degree of linear relationship or dependency between them. Having highly correlated features can introduce multicollinearity in a model, which can affect the model's performance and interpretability."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "other featuers are not correlated to each other, Correlated features are not considered important because they can introduce redundancy, affect model interpretability, lead to model instability, and increase the risk of overfitting. Selecting uncorrelated features can improve model performance, enhance interpretability, and ensure more reliable and generalized results."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6-CH1ZPkuc-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the distplots without any transformation\n",
        "\n",
        "for col in X_train.columns:\n",
        "    plt.figure(figsize=(14,4))\n",
        "    plt.subplot(121)\n",
        "    sns.distplot(X_train[col])\n",
        "    plt.title(col)\n",
        "\n",
        "    plt.subplot(122)\n",
        "    stats.probplot(X_train[col], dist=\"norm\", plot=plt)\n",
        "    plt.title(col)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "A7cV0qXslB7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "# Apply Yeo-Johnson transform\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import pandas as pd\n",
        "\n",
        "pt1 = PowerTransformer()\n",
        "X_train_transformed2 = pt1.fit_transform(X_train)\n",
        "X_test_transformed2 = pt1.transform(X_test)\n",
        "\n",
        "lr = LinearRegression()\n",
        "\n",
        "# Perform cross-validation with 5 folds\n",
        "cv_scores = cross_val_score(lr, X_train_transformed2, y_train, cv=5, scoring='r2')\n",
        "\n",
        "# Train the model on the full training set\n",
        "lr.fit(X_train_transformed2, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred3 = lr.predict(X_test_transformed2)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred3)\n",
        "print(\"R-squared score:\", r2)\n",
        "\n",
        "df = pd.DataFrame({'cols': X_train.columns, 'Yeo_Johnson_lambdas': pt1.lambdas_})\n",
        "# print(df)\n",
        "\n",
        "print(\"Cross-validated R-squared scores:\", cv_scores)\n",
        "print(\"Mean R-squared score:\", cv_scores.mean())\n",
        "mean_r2 = np.mean(cv_scores)\n",
        "print(\"Mean R-squared score:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "rCk44k3QOqIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# pd.DataFrame({'cols':X_train.columns,'Yeo_Johnson_lambdas':pt1.lambdas_})"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_transformed = pd.DataFrame(X_train_transformed2,columns=X_train.columns)\n",
        "\n",
        "for col in X_train_transformed.columns:\n",
        "    plt.figure(figsize=(14,4))\n",
        "    plt.subplot(121)\n",
        "    sns.distplot(X_train[col])\n",
        "    plt.title(col)\n",
        "\n",
        "    plt.subplot(122)\n",
        "    sns.distplot(X_train_transformed[col])\n",
        "    plt.title(col)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "BTkrb60jmEsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# fit the scaler to the train set, it will learn the parameters\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# transform train and test sets\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Instantiate a LinearRegression model\n",
        "lr = LinearRegression()\n",
        "\n",
        "# Fit the model using the scaled features (X_train_scaled) and the continuous labels (y_train)\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = lr.predict(X_test_scaled)\n",
        "\n",
        "# Calculate the mean squared error (MSE) on the test set\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Assuming y_test contains the true target values and y_pred contains the predicted values\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared score:\", r2)\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Assuming X_train_scaled and y_train contain the scaled training data and target values, respectively\n",
        "# Assuming lr is your trained linear regression model\n",
        "\n",
        "# Perform cross-validation with 5 folds\n",
        "cv_scores = cross_val_score(lr, X_train_scaled, y_train, cv=5, scoring='r2')\n",
        "\n",
        "# Print the cross-validated R-squared scores\n",
        "print(\"Cross-validated R-squared scores:\", cv_scores)\n",
        "print(\"Mean R-squared score:\", cv_scores.mean())\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "ZHQHWGyZax3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
      ],
      "metadata": {
        "id": "6RwKqMsZCZG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n",
        "\n",
        "ax1.scatter(X_train['Visibility'], X_train['Temperature'])\n",
        "ax1.set_title(\"Before Scaling\")\n",
        "ax2.scatter(X_train_scaled['Visibility'], X_train_scaled['Temperature'],color='red')\n",
        "ax2.set_title(\"After Scaling\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fdUiw4bxCurQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n",
        "\n",
        "# before scaling\n",
        "ax1.set_title('Before Scaling')\n",
        "sns.kdeplot(X_train['Visibility'], ax=ax1)\n",
        "sns.kdeplot(X_train['Temperature'], ax=ax1)\n",
        "\n",
        "# after scaling\n",
        "ax2.set_title('After Standard Scaling')\n",
        "sns.kdeplot(X_train_scaled['Visibility'], ax=ax2)\n",
        "sns.kdeplot(X_train_scaled['Temperature'], ax=ax2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8rwiREX6EiXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison of Distributions"
      ],
      "metadata": {
        "id": "T9_Gavx9E1wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n",
        "\n",
        "# before scaling\n",
        "ax1.set_title('Age Distribution Before Scaling')\n",
        "sns.kdeplot(X_train['Temperature'], ax=ax1)\n",
        "\n",
        "# after scaling\n",
        "ax2.set_title('Age Distribution After Standard Scaling')\n",
        "sns.kdeplot(X_train_scaled['Temperature'], ax=ax2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MTSqNjt_E36w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why scaling is important?"
      ],
      "metadata": {
        "id": "66hsd-K1FH25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "MinMaxScaler_scaler = MinMaxScaler()\n",
        "\n",
        "# fit the scaler to the train set, it will learn the parameters\n",
        "MinMaxScaler_scaler.fit(X_train)\n",
        "\n",
        "# transform train and test sets\n",
        "X_train_scaled_MinMaxScaler = MinMaxScaler_scaler.transform(X_train)\n",
        "X_test_scaled_MinMaxScaler = MinMaxScaler_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Create an instance of the LinearRegression model\n",
        "lr = LinearRegression()\n",
        "\n",
        "# Fit the model on the scaled training data\n",
        "lr.fit(X_train_scaled_MinMaxScaler, y_train)\n",
        "\n",
        "# Predict the target variable for the scaled test data\n",
        "y_pred_MinMaxScaler = lr.predict(X_test_scaled_MinMaxScaler)\n",
        "\n",
        "# Calculate the mean squared error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred_MinMaxScaler)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# Calculate the R-squared score\n",
        "r2 = r2_score(y_test, y_pred_MinMaxScaler)\n",
        "print(\"R-squared score:\", r2)\n",
        "\n",
        "# Perform cross-validation with 5 folds\n",
        "cv_scores_MinMaxScaler = cross_val_score(lr, X_train_scaled_MinMaxScaler, y_train, cv=5, scoring='r2')\n",
        "mean_r2_MinMaxScaler = np.mean(cv_scores_MinMaxScaler)\n",
        "print(\"Mean cross-validated R-squared score:\", mean_r2_MinMaxScaler)\n",
        "print(\"Mean R-squared score:\", cv_scores_MinMaxScaler.mean())\n"
      ],
      "metadata": {
        "id": "SXDrbpb8Jkh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled_MinMaxScaler = pd.DataFrame(X_train_scaled_MinMaxScaler, columns=X_train.columns)\n",
        "X_test_scaled_MinMaxScaler = pd.DataFrame(X_test_scaled_MinMaxScaler, columns=X_test.columns)"
      ],
      "metadata": {
        "id": "5q-bYRYqdFMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n",
        "\n",
        "ax1.scatter(X_train['Visibility'], X_train['Temperature'])\n",
        "ax1.set_title(\"Before Scaling\")\n",
        "ax2.scatter(X_train_scaled_MinMaxScaler['Visibility'], X_train_scaled_MinMaxScaler['Temperature'],color='red')\n",
        "ax2.set_title(\"After Scaling\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U5VAOz6Pcy7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n",
        "\n",
        "# before scaling\n",
        "ax1.set_title('Before Scaling')\n",
        "sns.kdeplot(X_train['Visibility'], ax=ax1)\n",
        "sns.kdeplot(X_train['Temperature'], ax=ax1)\n",
        "\n",
        "# after scaling\n",
        "ax2.set_title('After Standard Scaling')\n",
        "sns.kdeplot(X_train_scaled_MinMaxScaler['Visibility'], ax=ax2)\n",
        "sns.kdeplot(X_train_scaled_MinMaxScaler['Temperature'], ax=ax2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VXVKIXWEde-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n",
        "\n",
        "# before scaling\n",
        "ax1.set_title('Age Distribution Before Scaling')\n",
        "sns.kdeplot(X_train['Temperature'], ax=ax1)\n",
        "\n",
        "# after scaling\n",
        "ax2.set_title('Age Distribution After Standard Scaling')\n",
        "sns.kdeplot(X_train_scaled_MinMaxScaler['Temperature'], ax=ax2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o8dpSwR9dzCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I use standarization method just buecause this parform slitly better then normalization mathod"
      ],
      "metadata": {
        "id": "kAh9MR3YeJ1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## appling standardization method on model"
      ],
      "metadata": {
        "id": "4PnDZ6vme3Rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "U-vWgZD8fF3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"Curse of Dimensionality\" refers to the challenges that arise when dealing with high-dimensional data. It causes sparsity of data, increased computational complexity, overfitting, and difficulties with distance-based algorithms. Mitigation strategies include feature selection, dimensionality reduction, regularization, and leveraging domain knowledge."
      ],
      "metadata": {
        "id": "5154b1QEhqvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply PCA to the training set:"
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n"
      ],
      "metadata": {
        "id": "jH_0qkOz6Xi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,47):\n",
        "  pca = PCA(n_components=i)  # Specify the number of components to keep\n",
        "  X_train_pca = pca.fit_transform(X_train)\n",
        "#Fit a linear regression model on the transformed training set:\n",
        "  lrp = LinearRegression()\n",
        "  lrp.fit(X_train_pca, y_train)\n",
        "# Transform the test set using the same PCA transformation:\n",
        "  X_test_pca = pca.transform(X_test)\n",
        "# Make predictions on the transformed test set:\n",
        "  y_pred = lrp.predict(X_test_pca)\n",
        "# Evaluate the performance of the model using the R-squared score:\n",
        "  r2 = r2_score(y_test, y_pred)\n",
        "  print(\"R-squared score:\", r2)"
      ],
      "metadata": {
        "id": "dEThsA-A7cqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=42)  # Specify the number of components to keep\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "#Fit a linear regression model on the transformed training set:\n",
        "lrp = LinearRegression()\n",
        "lrp.fit(X_train_pca, y_train)\n",
        "# Transform the test set using the same PCA transformation:\n",
        "X_test_pca = pca.transform(X_test)\n",
        "# Make predictions on the transformed test set:\n",
        "y_pred = lrp.predict(X_test_pca)\n",
        "# Evaluate the performance of the model using the R-squared score:\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared score:\", r2)\n"
      ],
      "metadata": {
        "id": "ag0oju0VuBuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transforming in 3D\n",
        "pca = PCA(n_components=3)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)"
      ],
      "metadata": {
        "id": "5jGDu0l4-LHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "y_train_pca = y_train.astype(str)\n",
        "fig = px.scatter_3d(df, x=X_train_pca[:,0], y=X_train_pca[:,1], z=X_train_pca[:,2],\n",
        "              color=y_train_pca)\n",
        "fig.update_layout(\n",
        "    margin=dict(l=20, r=20, t=20, b=20),\n",
        "    paper_bgcolor=\"LightSteelBlue\",\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "MW7T8_Q5-eid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))"
      ],
      "metadata": {
        "id": "7ydmr7qT85WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "# Fit the Algorithm\n",
        "reg= LinearRegression()\n",
        "reg.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the score\n",
        "reg.score(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "t5lPz2SrYlwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "#get the X_train and X-test value\n",
        "y_pred_train=reg.predict(X_train)\n",
        "y_pred_test=reg.predict(X_test)\n",
        "print(\"Predicted target values:\", y_pred_test)"
      ],
      "metadata": {
        "id": "3h8BHtLTYbVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate the evaluation metric scores\n",
        "train_score = r2_score(y_train, y_pred_train)\n",
        "print(train_score)\n",
        "test_score = r2_score(y_test, y_pred_test)\n",
        "print(test_score)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross checking with cross val score\n",
        "np.mean(cross_val_score(reg,X_train, y_train,scoring='r2',cv=10))"
      ],
      "metadata": {
        "id": "JqBosqDxR9Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STbYFr4xcs3u"
      },
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_lr= mean_squared_error((y_train), (y_pred_train))\n",
        "print(\"MSE :\",MSE_lr)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_lr=np.sqrt(MSE_lr)\n",
        "print(\"RMSE :\",RMSE_lr)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_lr= mean_absolute_error(y_train, y_pred_train)\n",
        "print(\"MAE :\",MAE_lr)\n",
        "\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_lr= r2_score(y_train, y_pred_train)\n",
        "print(\"R2 :\",r2_lr)\n",
        "Adjusted_R2_lr = (1-(1-r2_score(y_train, y_pred_train))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WnqF_7IWo1pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# Define the parameter grid for GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'fit_intercept': [True, False],\n",
        "}\n",
        "\n",
        "# Fit the Algorithm\n",
        "# Perform GridSearchCV with cross-validation\n",
        "grid_search = GridSearchCV(reg, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "# Print the best parameters and best score\n",
        "print(\"Best Parameters: \", grid_search.best_params_)\n",
        "print(\"Best Score: \", grid_search.best_score_)"
      ],
      "metadata": {
        "id": "gdiUKBpapzs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Perform cross-validation with the best estimator\n",
        "linear_regression_best = grid_search.best_estimator_\n",
        "cv_scores = cross_val_score(linear_regression_best, X_train, y_train, cv=10)\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean CV Score:\", cv_scores.mean())\n",
        "\n",
        "# Fit the best estimator on the training data\n",
        "linear_regression_best.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "test_score = linear_regression_best.score(X_test, y_test)\n",
        "print(\"Test Score:\", test_score)"
      ],
      "metadata": {
        "id": "pkBp5w-hQoa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DECISION TREE**"
      ],
      "metadata": {
        "id": "tCdtO__zTzpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "decision_regressor = DecisionTreeRegressor(max_depth=None,\n",
        "                                           max_features=12,\n",
        "                                           max_leaf_nodes=150)\n",
        "\n",
        "# Fit the Algorithm\n",
        "decision_regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "HLjCjUesT_Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#get the X_train and X-test value\n",
        "y_pred_train_d = decision_regressor.predict(X_train)\n",
        "y_pred_test_d = decision_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "bNUiYRWoUV9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "decision_regressor.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "t7LDKyvRcfC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Model Score:\",decision_regressor.score(X_train,y_train))\n",
        "\n",
        "#calculate MSE\n",
        "MSE_d= mean_squared_error(y_train, y_pred_train_d)\n",
        "print(\"MSE :\",MSE_d)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_d=np.sqrt(MSE_d)\n",
        "print(\"RMSE :\",RMSE_d)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_d= mean_absolute_error(y_train, y_pred_train_d)\n",
        "print(\"MAE :\",MAE_d)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_d= r2_score(y_train, y_pred_train_d)\n",
        "print(\"R2 :\",r2_d)\n",
        "Adjusted_R2_d=(1-(1-r2_score(y_train, y_pred_train_d))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_d))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for importance, name in sorted(zip(decision_regressor.feature_importances_, X_train.columns), reverse = True):\n",
        "  #print (name,importance)\n"
      ],
      "metadata": {
        "id": "h_j6EMzDv7fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'max_depth': [None, 5,8,9, 10, 15,16],\n",
        "    'max_features': [2, 5,9,10,12],\n",
        "    'max_leaf_nodes': [100,150,180]\n",
        "}\n"
      ],
      "metadata": {
        "id": "gj4pf1DzrpsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform cross-validation with GridSearchCV\n",
        "# Create the grid search object\n",
        "grid_search = GridSearchCV(decision_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the grid search object to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best estimator from grid search\n",
        "best_regressor = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "y_pred = best_regressor.predict(X_test)\n",
        "\n",
        "# Calculate the mean squared error on the test set\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# Print the best parameters found by grid search\n",
        "print(\"Best Parameters:\", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "9y6vd8tyse9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best parameters and best score\n",
        "print(\"Best Parameters: \", grid_search.best_params_)\n",
        "print(\"Best Score: \", grid_search.best_score_)\n",
        "\n"
      ],
      "metadata": {
        "id": "i7v-3vI-su_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "accuracy = best_model.score(X_test, y_test)\n",
        "print(\"Test Accuracy: \", accuracy)\n"
      ],
      "metadata": {
        "id": "bsD7fLRl4Zar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform cross-validation with best parameters\n",
        "cross_val_scores = cross_val_score(best_model, X, y, cv=5)\n",
        "print(\"Cross-Validation Scores: \", cross_val_scores)\n",
        "print(\"Average Cross-Validation Score: \", cross_val_scores.mean())"
      ],
      "metadata": {
        "id": "33M5zA0_s81J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RandomForestRegressor"
      ],
      "metadata": {
        "id": "nsGqMgn6W2Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "#import the packages\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Create an instance of the RandomForestRegressor\n",
        "rf_model = RandomForestRegressor()"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the Algorithm\n",
        "rf_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "AZ_Cb631Ly4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "\n",
        "y_pred_train_r = rf_model.predict(X_train)\n",
        "y_pred_test_r = rf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "Wdn4UAa5L9Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "Ka5kgIgux17A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform cross-validation\n",
        "scores = cross_val_score(rf_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
        "rmse_scores = np.sqrt(-scores)\n",
        "\n",
        "print(\"Root Mean Squared Error scores:\", rmse_scores)\n",
        "print(\"Average RMSE score:\", np.mean(rmse_scores))"
      ],
      "metadata": {
        "id": "buVIhwFM57_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Model Score:\",rf_model.score(X_train,y_train))\n",
        "\n",
        "#calculate MSE\n",
        "MSE_rf= mean_squared_error(y_train, y_pred_train_r)\n",
        "print(\"MSE :\",MSE_rf)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_rf=np.sqrt(MSE_rf)\n",
        "print(\"RMSE :\",RMSE_rf)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_rf= mean_absolute_error(y_train, y_pred_train_r)\n",
        "print(\"MAE :\",MAE_rf)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_rf= r2_score(y_train, y_pred_train_r)\n",
        "print(\"R2 :\",r2_rf)\n",
        "Adjusted_R2_rf=(1-(1-r2_score(y_train, y_pred_train_r))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_r))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# Number of trees in random forest\n",
        "n_estimators = [20,60,100,120]\n",
        "\n",
        "# Number of features to consider at every split\n",
        "max_features = [0.2,0.6,1.0]\n",
        "\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [2,8,None]\n",
        "\n",
        "# Number of samples\n",
        "max_samples = [0.5,0.75,1.0]\n",
        "\n",
        "# Bootstrap samples\n",
        "bootstrap = [True,False]\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2]\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "              'max_samples':max_samples,\n",
        "              'bootstrap':bootstrap,\n",
        "              'min_samples_split':min_samples_split,\n",
        "              'min_samples_leaf':min_samples_leaf\n",
        "             }\n",
        "print(param_grid)"
      ],
      "metadata": {
        "id": "IS6-ixkYZUP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "rf_grid = RandomizedSearchCV(estimator = rf_model,\n",
        "                       param_distributions = param_grid,\n",
        "                       cv = 5,\n",
        "                       verbose=2,\n",
        "                       n_jobs = -1)"
      ],
      "metadata": {
        "id": "75K8xqpAZY77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_grid.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "1Oj-GIEmZbRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_grid.best_params_"
      ],
      "metadata": {
        "id": "jPKOw22MZdio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_grid.best_score_"
      ],
      "metadata": {
        "id": "XEe0mAz4a2Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}